{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import efficientnet_b3, resnet50\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Allocated:\", torch.cuda.memory_allocated(0) / (1024 ** 3), \"GiB\")\n",
    "print(\"Reserved:\", torch.cuda.memory_reserved(0) / (1024 ** 3), \"GiB\")\n",
    "\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (640, 640)\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "NUM_CLASSES = 7\n",
    "LEARNING_RATE = 0.0001\n",
    "TEST_SPLIT = 0.1\n",
    "plt.style.use('ggplot')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio=8):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction_ratio, channels)\n",
    "        )\n",
    "\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.mlp(self.avg_pool(x).view(-1, self.channels))\n",
    "        max_out = self.mlp(self.max_pool(x).view(-1, self.channels))\n",
    "        channel_out = self.sigmoid(avg_out + max_out).view(-1, self.channels, 1, 1)\n",
    "        x = x * channel_out\n",
    "\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_out = self.sigmoid(self.conv(concat))\n",
    "        x = x * spatial_out\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GeoKnowr(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(GeoKnowr, self).__init__()\n",
    "\n",
    "        self.effnet = efficientnet_b3(weights='DEFAULT')\n",
    "        self.resnet = resnet50(weights='DEFAULT')\n",
    "\n",
    "        self.effnet_features = nn.Sequential(*list(self.effnet.children())[:-2])\n",
    "        self.resnet_features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "        self.effnet_conv = nn.Conv2d(1536, 512, kernel_size=1)\n",
    "        self.resnet_conv = nn.Conv2d(2048, 512, kernel_size=1)\n",
    "\n",
    "        self.cbam1 = CBAM(512)\n",
    "        self.conv = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(512)\n",
    "        self.cbam2 = CBAM(512)\n",
    "\n",
    "        self.continent_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        self.coord_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet_conv(self.effnet_features(x))\n",
    "        res_features = self.resnet_conv(self.resnet_features(x))\n",
    "\n",
    "        fused_features = eff_features + res_features\n",
    "\n",
    "        x = self.cbam1(fused_features)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.cbam2(x)\n",
    "\n",
    "        x = torch.mean(x, dim=[2, 3])\n",
    "\n",
    "        continent_out = self.continent_head(x)\n",
    "        coord_out = self.coord_head(x)\n",
    "\n",
    "        return continent_out, coord_out\n",
    "\n",
    "\n",
    "class GeoDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        continent = self.df.iloc[idx]['continent_encoded']\n",
    "        coords = self.df.iloc[idx][['lat_norm', 'lon_norm']].values.astype(np.float32)\n",
    "\n",
    "        return image, (continent, coords)\n",
    "\n",
    "\n",
    "def prepare_data(csv_path, image_dir):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Found {len(df)} entries in CSV\")\n",
    "\n",
    "        image_paths = []\n",
    "        for i, row in df.iterrows():\n",
    "            possible_paths = [\n",
    "                os.path.join(image_dir, f\"{i}.png\"),\n",
    "                os.path.join(image_dir, f\"{i}.jpg\"),\n",
    "                os.path.join(image_dir, f\"{row['latitude']:.6f}_{row['longitude']:.6f}.png\"),\n",
    "                os.path.join(image_dir, f\"image_{i}.png\")\n",
    "            ]\n",
    "\n",
    "            for path in possible_paths:\n",
    "                if os.path.exists(path):\n",
    "                    image_paths.append(path)\n",
    "                    break\n",
    "            else:\n",
    "                image_paths.append(\"\")\n",
    "\n",
    "        df['image_path'] = image_paths\n",
    "        df['image_exists'] = df['image_path'].apply(lambda x: os.path.exists(x) if x else False)\n",
    "\n",
    "        print(f\"\\nImage status:\")\n",
    "        print(f\"- Found: {df['image_exists'].sum()}\")\n",
    "        print(f\"- Missing: {len(df) - df['image_exists'].sum()}\")\n",
    "\n",
    "        if df['image_exists'].sum() == 0:\n",
    "            try:\n",
    "                sample_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg'))][:5]\n",
    "                print(f\"Sample files in directory: {sample_files}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not list directory contents: {str(e)}\")\n",
    "            raise ValueError(\"No matching images found. Please check the image naming pattern.\")\n",
    "\n",
    "        df = df[df['image_exists']].copy()\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        df['continent_encoded'] = le.fit_transform(df['continent'])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        coords = df[['latitude', 'longitude']].values\n",
    "        df[['lat_norm', 'lon_norm']] = scaler.fit_transform(coords)\n",
    "\n",
    "        # Split into train/val/test\n",
    "        train_df = df.sample(frac=0.7, random_state=42)  # 70% train\n",
    "        val_df = df.drop(train_df.index).sample(frac=0.67, random_state=42)  # 20% val\n",
    "        test_df = df.drop(train_df.index).drop(val_df.index)  # 10% test\n",
    "\n",
    "        print(\"\\nData split:\")\n",
    "        print(f\"- Training samples: {len(train_df)}\")\n",
    "        print(f\"- Validation samples: {len(val_df)}\")\n",
    "        print(f\"- Test samples: {len(test_df)}\")\n",
    "\n",
    "        return train_df, val_df, test_df, le, scaler\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prepare_data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "def evaluate_test(model, test_loader, le):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_reg = nn.HuberLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, (continents, coords) in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(DEVICE)\n",
    "            continents = continents.long().to(DEVICE)\n",
    "            coords = coords.to(DEVICE)\n",
    "\n",
    "            continent_pred, coord_pred = model(images)\n",
    "            loss_cls = criterion_cls(continent_pred, continents)\n",
    "            loss_reg = criterion_reg(coord_pred, coords)\n",
    "            test_loss += 0.6 * loss_cls.item() + 0.4 * loss_reg.item()\n",
    "\n",
    "            _, predicted = torch.max(continent_pred.data, 1)\n",
    "            total += continents.size(0)\n",
    "            correct += (predicted == continents).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(continents.cpu().numpy())\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(all_true, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d',\n",
    "                xticklabels=le.classes_,\n",
    "                yticklabels=le.classes_,\n",
    "                cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "def train():\n",
    "    try:\n",
    "        print(\"Downloading dataset...\")\n",
    "        dataset_path = kagglehub.dataset_download(\"ayuseless/streetview-image-dataset\")\n",
    "        print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "        image_dir = None\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            if any(f.lower().endswith(('.png', '.jpg')) for f in files):\n",
    "                image_dir = root\n",
    "                break\n",
    "\n",
    "        if image_dir is None:\n",
    "            print(\"\\nDirectory structure:\")\n",
    "            os.system(f\"tree -L 3 {dataset_path}\")\n",
    "            raise FileNotFoundError(\"Could not find any images in the downloaded dataset\")\n",
    "\n",
    "        print(f\"\\nFound images in: {image_dir}\")\n",
    "\n",
    "        csv_path = os.path.join(\"data\", \"coordinates_with_continents_mapbox.csv\")\n",
    "        if not os.path.exists(csv_path):\n",
    "            csv_path = \"coordinates_with_continents_mapbox.csv\"\n",
    "\n",
    "        print(\"\\nVerifying paths:\")\n",
    "        print(f\"CSV path: {os.path.abspath(csv_path)}\")\n",
    "        print(f\"Image dir: {image_dir}\")\n",
    "        print(f\"Sample image files: {os.listdir(image_dir)[:5]}\")\n",
    "\n",
    "        print(\"\\nPreparing data...\")\n",
    "        train_df, val_df, test_df, le, scaler = prepare_data(csv_path, image_dir)\n",
    "\n",
    "        train_dataset = GeoDataset(train_df, transform=get_transforms())\n",
    "        val_dataset = GeoDataset(val_df, transform=get_transforms())\n",
    "        test_dataset = GeoDataset(test_df, transform=get_transforms())\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "        print(\"Initializing model...\")\n",
    "        model = GeoKnowr(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "        print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "        criterion_cls = nn.CrossEntropyLoss()\n",
    "        criterion_reg = nn.HuberLoss()\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            model.train()\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Train]\", leave=False)\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for images, (continents, coords) in train_pbar:\n",
    "                images = images.to(DEVICE)\n",
    "                continents = continents.long().to(DEVICE)\n",
    "                coords = coords.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                continent_pred, coord_pred = model(images)\n",
    "\n",
    "                loss_cls = criterion_cls(continent_pred, continents)\n",
    "                loss_reg = criterion_reg(coord_pred, coords)\n",
    "                loss = 0.6 * loss_cls + 0.4 * loss_reg\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_pbar.set_postfix({\n",
    "                    \"Loss\": f\"{loss.item():.4f}\",\n",
    "                    \"Avg Loss\": f\"{train_loss / (train_pbar.n + 1):.4f}\"\n",
    "                })\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS} [Val]\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for images, (continents, coords) in val_pbar:\n",
    "                    images = images.to(DEVICE)\n",
    "                    continents = continents.long().to(DEVICE)\n",
    "                    coords = coords.to(DEVICE)\n",
    "\n",
    "                    continent_pred, coord_pred = model(images)\n",
    "                    loss_cls = criterion_cls(continent_pred, continents)\n",
    "                    loss_reg = criterion_reg(coord_pred, coords)\n",
    "                    val_loss += 0.6 * loss_cls.item() + 0.4 * loss_reg.item()\n",
    "\n",
    "                    _, predicted = torch.max(continent_pred.data, 1)\n",
    "                    total += continents.size(0)\n",
    "                    correct += (predicted == continents).sum().item()\n",
    "\n",
    "                    val_pbar.set_postfix({\n",
    "                        \"Acc\": f\"{100 * correct / total:.2f}%\",\n",
    "                        \"Val Loss\": f\"{val_loss / (val_pbar.n + 1):.4f}\"\n",
    "                    })\n",
    "\n",
    "            # Store epoch metrics\n",
    "            train_losses.append(train_loss / len(train_loader))\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(100 * correct / total)\n",
    "\n",
    "            print(f\"\\nEpoch {epoch + 1}/{EPOCHS} Summary:\")\n",
    "            print(f\"Train Loss: {train_losses[-1]:.4f}\")\n",
    "            print(f\"Val Loss: {val_losses[-1]:.4f}\")\n",
    "            print(f\"Val Accuracy: {val_accuracies[-1]:.2f}%\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "        # Plot training curves\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, 'b-o', label='Train Loss')\n",
    "        plt.plot(val_losses, 'r-o', label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_accuracies, 'g-o', label='Val Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Test evaluation\n",
    "        test_acc = evaluate_test(model, test_loader, le)\n",
    "\n",
    "        # Save model\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'le_classes': le.classes_,\n",
    "            'scaler_mean': scaler.mean_,\n",
    "            'scaler_scale': scaler.scale_,\n",
    "            'test_accuracy': test_acc,\n",
    "            'training_metrics': {\n",
    "                'train_loss': train_losses,\n",
    "                'val_loss': val_losses,\n",
    "                'val_acc': val_accuracies\n",
    "            }\n",
    "        }, \"geoknowr_model.pth\")\n",
    "\n",
    "        print(\"\\nTraining complete!\")\n",
    "        print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
    "        print(\"Visualizations saved:\")\n",
    "        print(\"- confusion_matrix.png\")\n",
    "        print(\"- training_curves.png\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
