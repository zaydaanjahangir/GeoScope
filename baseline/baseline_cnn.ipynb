{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77733127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from cnn import * \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class StreetviewDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data['continent'] = self.data['continent'].astype(str)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        continents = sorted(self.data['continent'].unique())\n",
    "        self.label_map = {label: idx for idx, label in enumerate(continents)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, f\"{idx}.png\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Get the label from the 'continent' column\n",
    "        label_str = self.data.iloc[idx]['continent']\n",
    "        label = self.label_map[label_str]\n",
    "        return image, label\n",
    "\n",
    "# Data preprocessing: transforms for RGB images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize each channel\n",
    "])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Split dataset into train, validation, and test 70/10/20 split\n",
    "dataset = StreetviewDataset(csv_file=\"data/coordinates_with_continents_mapbox.csv\", \n",
    "                              img_dir=\"Streetview_Image_Dataset\", \n",
    "                              transform=transform)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Instantiate CNN model \n",
    "conv_net = Conv_Net()\n",
    "conv_net.to(device)\n",
    "\n",
    "# Loss function and optimizer (Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_cnn = optim.Adam(conv_net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "cnn_train_losses = []\n",
    "cnn_val_losses = []\n",
    "cnn_val_accs = []  # List to record validation accuracy per epoch\n",
    "best_val_acc = 0.0  # To track the best validation accuracy\n",
    "best_epoch = 0      # To track which epoch had the best accuracy\n",
    "num_epochs_cnn = 15\n",
    "\n",
    "# Training loop with live validation evaluation\n",
    "for epoch in range(num_epochs_cnn):\n",
    "    running_loss_cnn = 0.0\n",
    "    conv_net.train()\n",
    "    \n",
    "    for i, data in enumerate(tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs_cnn}\"), 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer_cnn.zero_grad()\n",
    "        outputs = conv_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cnn.step()\n",
    "        running_loss_cnn += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss_cnn / len(trainloader)\n",
    "    cnn_train_losses.append(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs_cnn}, CNN Training Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    conv_net.eval()\n",
    "    val_loss = 0.0\n",
    "    total_val = 0\n",
    "    correct_val = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valloader, desc=\"Validation\"):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = conv_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(valloader)\n",
    "    val_acc = correct_val / total_val\n",
    "    cnn_val_losses.append(val_loss)\n",
    "    cnn_val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs_cnn}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    # Checkpoint if current validation accuracy is the best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(conv_net.state_dict(), 'best_cnn.pth')\n",
    "        print(f\"Checkpoint: Saving best model at epoch {epoch+1} with validation accuracy {val_acc:.4f}\")\n",
    "\n",
    "print('Finished Training CNN')\n",
    "\n",
    "torch.save(conv_net.state_dict(), 'cnn.pth') \n",
    "\n",
    "# Evaluate accuracy on the test set after training\n",
    "correct_cnn = 0\n",
    "total_cnn = 0\n",
    "conv_net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testloader, desc=\"Evaluating Test Set\"):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs_cnn = conv_net(images)\n",
    "        _, predicted_cnn = torch.max(outputs_cnn, 1)\n",
    "        total_cnn += labels.size(0)\n",
    "        correct_cnn += (predicted_cnn == labels).sum().item()\n",
    "\n",
    "print('Accuracy for CNN on Test Set: ', correct_cnn / total_cnn)\n",
    "\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs_cnn + 1), cnn_train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs_cnn + 1), cnn_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('CNN Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig('cnn_loss.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs_cnn + 1), cnn_val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('CNN Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('cnn_accuracy.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
